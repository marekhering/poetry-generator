{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import typing as tp\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.optimizers\n",
    "import keras.callbacks\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TO_EXCLUDE = '!\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~.,:;!?\\t'\n",
    "TO_TOKENIZE = '\\n'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 57127.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap'n jack was washed over the side \n",
      " his crew searched but found not hair nor hide \n",
      " no longer the helm \n",
      " but the deep benthic realm \n",
      " is where jack will forever reside \n",
      "  \n",
      " ablactation to wean off the breast \n",
      " should wait 'til age 2 this is best \n",
      " though some men never quit \n",
      " bet you thought i'd rhyme tit \n",
      " because they're mammarially obsessed \n",
      "  \n",
      " as a soup bisque is best when served hot \n",
      " made with lobster it hits the right spot \n",
      " i think it tastes dreamy \n",
      " it's so rich and creamy \n",
      " it's the soup you'd be served on a yacht \n",
      "  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(file, include: str, exclude: str, size: int = None):\n",
    "    _text =  []\n",
    "    with open(file) as f:\n",
    "        data = csv.reader(f)\n",
    "        for verse, *_ in tqdm(list(data)[:size] if size is not None else list(data)):\n",
    "            # Separate characters that we want to tokenize\n",
    "            correct_verse = re.sub(r'(['+include+'])', r' \\1 ', verse)\n",
    "            # Exclude characters that we do not want to tokenize\n",
    "            correct_verse = correct_verse.translate(str.maketrans('', '', exclude))\n",
    "            _text.append(correct_verse.lower() + ' \\n')\n",
    "    return _text\n",
    "\n",
    "TEXT = load_data('data/poems/limericks.csv', TO_TOKENIZE, TO_EXCLUDE, 4000)\n",
    "print(*TEXT[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 31561.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "abodes: ['modes']\n",
      " abolish: ['demolish', 'polish']\n",
      " abortive: ['supportive', 'contortive']\n",
      " abound: ['ground', 'round', 'astound', 'underground', 'found', 'drowned', 'unsound', 'around', 'blackcrowned', 'sound']\n",
      " abounding: ['astounding', 'dumbfounding']\n",
      " about: ['doubt', 'out', 'shout']\n",
      " aboutface: ['disgrace', 'erase']\n",
      " above: ['guv', 'dove', 'shove', 'love']\n",
      " abracadabra: ['zebra']\n",
      " abrachiocephalia: ['yer']\n",
      "\n",
      "...\n",
      "Most common rhyme: 'me' | Length: 55 | Rhymes: ['xslt', 'he', 'e', 'see', 'g', 'crueltyfree', 'debris', 'glee', 'be', 'bea'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_rhymes(_text: tp.List[str]):\n",
    "    rhymes = defaultdict(list)\n",
    "\n",
    "    def add_rhymes(rhyme_words: tp.List[str]):\n",
    "        for word in rhyme_words:\n",
    "            others = rhyme_words.copy()\n",
    "            others.remove(word)\n",
    "            rhymes[word].extend(others)\n",
    "\n",
    "    for verse in tqdm(_text):\n",
    "        lines = verse.strip().split('\\n')\n",
    "        try:\n",
    "            last_words = [line.strip().split(' ')[-1] for line in lines]\n",
    "            # The rhyme scheme in the limerick is aabba\n",
    "            a_rhymes = [last_words[0], last_words[1], last_words[4]]\n",
    "            b_rhymes = [last_words[2], last_words[3]]\n",
    "            add_rhymes(a_rhymes)\n",
    "            add_rhymes(b_rhymes)\n",
    "        except IndexError:\n",
    "            # Invalid limerick\n",
    "            continue\n",
    "    return {k: list(set(v)) for k, v in rhymes.items()}\n",
    "\n",
    "RHYMES = extract_rhymes(TEXT)\n",
    "print(\"...\")\n",
    "print(*[f\"{k}: {v}\\n\" for k, v in sorted(RHYMES.items())[100:110]])\n",
    "print(\"...\")\n",
    "most_common = max(RHYMES.keys(), key=lambda x: len(RHYMES[x]))\n",
    "print(f\"Most common rhyme: '{most_common}' | Length: {len(RHYMES[most_common])} | Rhymes: {RHYMES[most_common][:10]} ...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{' ': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 's': 6, 'i': 7, 'n': 8, 'r': 9, 'h': 10, '\\n': 11, 'l': 12, 'd': 13, 'u': 14, 'c': 15, 'm': 16, 'w': 17, 'y': 18, 'g': 19, 'f': 20, 'p': 21, 'b': 22, \"'\": 23, 'k': 24, 'v': 25, 'j': 26, 'x': 27, 'q': 28, 'z': 29, '1': 30, '2': 31, '0': 32, '3': 33, '4': 34, '9': 35, '6': 36, '8': 37, '7': 38, '5': 39}\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = Tokenizer(filters=TO_EXCLUDE, char_level=True)\n",
    "TOKENIZER.fit_on_texts(TEXT)\n",
    "TOTAL_CHARS = len(TOKENIZER.word_index) + 1\n",
    "print(TOTAL_CHARS)\n",
    "print(TOKENIZER.word_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8572/8572 [00:00<00:00, 10840.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 161304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(rhymes: tp.Dict[str, tp.List[str]], tokenizer: Tokenizer, total_chars: int):\n",
    "    sequences = []\n",
    "    for base_word, rhymes_words in tqdm(rhymes.items()):\n",
    "        for rhyme_word in rhymes_words:\n",
    "            seq = f\"{base_word} {rhyme_word} \"\n",
    "            encoded = tokenizer.texts_to_sequences(seq)\n",
    "            for i in range(len(base_word) + 2, len(encoded) + 1):\n",
    "                sequences.append(encoded[:i])\n",
    "    return sequences\n",
    "\n",
    "SEQUENCES = create_sequences(RHYMES, TOKENIZER, TOTAL_CHARS)\n",
    "print(f\"Size of training set {len(SEQUENCES)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 62\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = max([len(seq) for seq in SEQUENCES])\n",
    "ENCODED_SEQUENCES = pad_sequences(SEQUENCES, maxlen=SEQUENCE_LENGTH, padding='pre')\n",
    "X, y = ENCODED_SEQUENCES[:,:-1], to_categorical(ENCODED_SEQUENCES[:,-1], num_classes=TOTAL_CHARS)\n",
    "print(f'Max Sequence Length: {SEQUENCE_LENGTH}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 1, 100)            4000      \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 1, 64)             42240     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 1, 32)             12416     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 1, 32)             8320      \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 40)                1320      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,616\n",
      "Trainable params: 76,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_model(total_chars: int, sequence_length: int):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Embedding(total_chars, 100, input_length=sequence_length - 1))\n",
    "    model.add(keras.layers.LSTM(64, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(32, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(32, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(total_chars, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "MODEL_NAME = \"RhymeModel2\"\n",
    "MODEL_PATH = f\"data/models/{MODEL_NAME}/weights.h5\"\n",
    "MODEL = keras.models.load_model(MODEL_PATH)\n",
    "# MODEL = create_model(TOTAL_CHARS, SEQUENCE_LENGTH)\n",
    "print(MODEL.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "REVERSE_TOKEN_INDEX = {v: k for k, v in TOKENIZER.word_index.items()}\n",
    "\n",
    "def generate_rhyme(model: keras.Model, sequence_length: int, in_word: str):\n",
    "    in_word = in_word + \" \" if in_word[-1] != \" \" else in_word\n",
    "    for i in range(20):\n",
    "        encoded = TOKENIZER.texts_to_sequences([in_word])[0]\n",
    "        padded = pad_sequences([encoded], maxlen=sequence_length - 1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(padded, verbose=0))\n",
    "        out_char = REVERSE_TOKEN_INDEX.get(predicted, None)\n",
    "        if out_char == \" \" or out_char is None:\n",
    "            break\n",
    "        in_word += out_char\n",
    "    return in_word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    callbacks = []\n",
    "\n",
    "    class PredictionCallback(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            frequency = 1\n",
    "            if epoch % frequency:\n",
    "                return\n",
    "            print()\n",
    "            print(generate_rhyme(MODEL, SEQUENCE_LENGTH, \"before\"))\n",
    "            print(generate_rhyme(MODEL, SEQUENCE_LENGTH, \"above\"))\n",
    "            print(generate_rhyme(MODEL, SEQUENCE_LENGTH, \"set\"))\n",
    "            print(generate_rhyme(MODEL, SEQUENCE_LENGTH, \"night\"))\n",
    "\n",
    "    callbacks.append(PredictionCallback())\n",
    "    callbacks.append(keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3))\n",
    "    callbacks.append(keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"data/models/{MODEL_NAME}/checkpoint\",\n",
    "        save_weights_only=True,\n",
    "        save_freq=5\n",
    "    ))\n",
    "    return callbacks\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "HISTORY = MODEL.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    callbacks=create_callbacks()\n",
    ")\n",
    "\n",
    "MODEL.save(MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheeked steeched\n",
      "age' ageagolagote\n",
      "exhort sort\n",
      "added sadder\n",
      "farewell stoll\n",
      "humerus sournes\n",
      "spritz sprits\n",
      "brill still\n",
      "craft aft\n",
      "backs max\n",
      "buff suff\n",
      "coyote aye\n",
      "artiste sumprist\n",
      "pledge aglee\n",
      "sir' sur\n",
      "wing sing\n",
      "apu shortoe\n",
      "rise sighs\n",
      "waltz coutpe\n",
      "atrocious dirious\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate_rhyme(MODEL, SEQUENCE_LENGTH, random.choice(list(RHYMES.keys()))))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open(f\"data/models/{MODEL_NAME}/tokenizer.pickle\", 'wb') as handle:\n",
    "    pickle.dump(TOKENIZER, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
