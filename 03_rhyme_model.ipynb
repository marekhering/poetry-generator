{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import typing as tp\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.optimizers\n",
    "import keras.callbacks\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TO_EXCLUDE = '!\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~.,:;!?\\t'\n",
    "TO_TOKENIZE = '\\n'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(file, include: str, exclude: str, size: int = None):\n",
    "    _text =  []\n",
    "    with open(file) as f:\n",
    "        data = csv.reader(f)\n",
    "        for verse, *_ in tqdm(list(data)[:size] if size is not None else list(data)):\n",
    "            # Separate characters that we want to tokenize\n",
    "            correct_verse = re.sub(r'(['+include+'])', r' \\1 ', verse)\n",
    "            # Exclude characters that we do not want to tokenize\n",
    "            correct_verse = correct_verse.translate(str.maketrans('', '', exclude))\n",
    "            _text.append(correct_verse.lower() + ' \\n')\n",
    "    return _text\n",
    "\n",
    "TEXT = load_data('data/poems/limericks.csv', TO_TOKENIZE, TO_EXCLUDE)\n",
    "print(*TEXT[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_rhymes(_text: tp.List[str]):\n",
    "    rhymes = defaultdict(list)\n",
    "\n",
    "    def add_rhymes(rhyme_words: tp.List[str]):\n",
    "        for word in rhyme_words:\n",
    "            others = rhyme_words.copy()\n",
    "            others.remove(word)\n",
    "            rhymes[word].extend(others)\n",
    "\n",
    "    for verse in tqdm(_text):\n",
    "        lines = verse.strip().split('\\n')\n",
    "        try:\n",
    "            last_words = [line.strip().split(' ')[-1] for line in lines]\n",
    "            # The rhyme scheme in the limerick is aabba\n",
    "            a_rhymes = [last_words[0], last_words[1], last_words[4]]\n",
    "            b_rhymes = [last_words[2], last_words[3]]\n",
    "            add_rhymes(a_rhymes)\n",
    "            add_rhymes(b_rhymes)\n",
    "        except IndexError:\n",
    "            # Invalid limerick\n",
    "            continue\n",
    "    return {k: list(set(v)) for k, v in rhymes.items()}\n",
    "\n",
    "RHYMES = extract_rhymes(TEXT)\n",
    "print(\"...\")\n",
    "print(*[f\"{k}: {v}\\n\" for k, v in sorted(RHYMES.items())[100:110]])\n",
    "print(\"...\")\n",
    "most_common = max(RHYMES.keys(), key=lambda x: len(RHYMES[x]))\n",
    "print(f\"Most common rhyme: '{most_common}' | Length: {len(RHYMES[most_common])} | Rhymes: {RHYMES[most_common][:10]} ...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOKENIZER = Tokenizer(filters=TO_EXCLUDE, char_level=True)\n",
    "TOKENIZER.fit_on_texts(TEXT)\n",
    "TOTAL_CHARS = len(TOKENIZER.word_index) + 1\n",
    "print(TOTAL_CHARS)\n",
    "print(TOKENIZER.word_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sequences(rhymes: tp.Dict[str, tp.List[str]], tokenizer: Tokenizer, total_chars: int):\n",
    "    sequences = []\n",
    "    for base_word, rhymes_words in tqdm(rhymes.items()):\n",
    "        for rhyme_word in rhymes_words:\n",
    "            seq = f\"{base_word} {rhyme_word} \"\n",
    "            encoded = tokenizer.texts_to_sequences(seq)\n",
    "            for i in range(len(base_word) + 2, len(encoded) + 1):\n",
    "                sequences.append(encoded[:i])\n",
    "    return sequences\n",
    "\n",
    "SEQUENCES = create_sequences(RHYMES, TOKENIZER, TOTAL_CHARS)\n",
    "print(f\"Size of training set {len(SEQUENCES)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = max([len(seq) for seq in SEQUENCES])\n",
    "ENCODED_SEQUENCES = pad_sequences(SEQUENCES, maxlen=SEQUENCE_LENGTH, padding='pre')\n",
    "X, y = ENCODED_SEQUENCES[:,:-1], to_categorical(ENCODED_SEQUENCES[:,-1], num_classes=TOTAL_CHARS)\n",
    "print(f'Max Sequence Length: {SEQUENCE_LENGTH}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(total_chars: int):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Embedding(total_chars, 100, input_length=1))\n",
    "    model.add(keras.layers.LSTM(64, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(64, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(64, return_sequences=True, activation='relu'))\n",
    "    model.add(keras.layers.LSTM(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(total_chars, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "MODEL_NAME = \"RhymeModel2\"\n",
    "MODEL = create_model(TOTAL_CHARS)\n",
    "print(MODEL.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "REVERSE_TOKEN_INDEX = {v: k for k, v in TOKENIZER.word_index.items()}\n",
    "\n",
    "class PredictionCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        frequency = 1\n",
    "        if epoch % frequency:\n",
    "            return\n",
    "\n",
    "        in_word = \"before \"\n",
    "        for i in range(10):\n",
    "            encoded = TOKENIZER.texts_to_sequences([in_word])[0]\n",
    "            padded = pad_sequences([encoded], maxlen=SEQUENCE_LENGTH - 1, padding='pre')\n",
    "            predicted = np.argmax(MODEL.predict(padded, verbose=0))\n",
    "            out_char = REVERSE_TOKEN_INDEX.get(predicted, None)\n",
    "            if out_char == \" \" or out_char is None:\n",
    "                break\n",
    "            in_word += out_char\n",
    "        print(f\"\\n{in_word}\")\n",
    "\n",
    "HISTORY = MODEL.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    callbacks=[PredictionCallback()]\n",
    ")\n",
    "\n",
    "MODEL.save(f\"data/models/{MODEL_NAME}/weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_rhyme(model: keras.Model, sequence_length: int, in_word: str):\n",
    "    in_word = in_word + \" \" if in_word[-1] != \" \" else in_word\n",
    "    for i in range(20):\n",
    "        encoded = TOKENIZER.texts_to_sequences([in_word])[0]\n",
    "        padded = pad_sequences([encoded], maxlen=sequence_length - 1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(padded, verbose=0))\n",
    "        out_char = REVERSE_TOKEN_INDEX.get(predicted, None)\n",
    "        if out_char == \" \" or out_char is None:\n",
    "            break\n",
    "        in_word += out_char\n",
    "    print(f\"{in_word}\")\n",
    "\n",
    "for _ in range(20):\n",
    "    generate_rhyme(MODEL, SEQUENCE_LENGTH, random.choice(list(RHYMES.keys())))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
